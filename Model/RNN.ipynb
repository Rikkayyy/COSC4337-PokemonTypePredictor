{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "326281f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6956bf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the finalized dataset\n",
    "df = pd.read_csv(\"../Datasets/pokedex_final.csv\")\n",
    "\n",
    "# Combine type1 and type2 into a list\n",
    "df['type_list'] = df[['type1', 'type2']].values.tolist()\n",
    "df['type_list'] = df['type_list'].apply(lambda x: [t for t in x if pd.notna(t) and t != ''])\n",
    "\n",
    "# Encode the types with MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(df['type_list'])\n",
    "\n",
    "# Tokenize the enhanced_info column\n",
    "text_tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
    "text_tokenizer.fit_on_texts(df['enhanced_info'])\n",
    "\n",
    "sequences = text_tokenizer.texts_to_sequences(df['enhanced_info'])\n",
    "X_text = pad_sequences(sequences, maxlen=300, padding='post', truncating='post')\n",
    "\n",
    "# Normalize numeric features\n",
    "stats_cols = ['hp', 'attack', 'defense', 's_attack', 'speed', 'height', 'weight']\n",
    "scaler = StandardScaler()\n",
    "X_stats = scaler.fit_transform(df[stats_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6f9723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " text_input (InputLayer)     [(None, 300)]                0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 300, 64)              320000    ['text_input[0][0]']          \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 64)                   33024     ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " stats_input (InputLayer)    [(None, 7)]                  0         []                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 71)                   0         ['lstm[0][0]',                \n",
      "                                                                     'stats_input[0][0]']         \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  9216      ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 18)                   2322      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 364562 (1.39 MB)\n",
      "Trainable params: 364562 (1.39 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 240ms/step - loss: 0.5091 - accuracy: 0.0500 - val_loss: 0.2964 - val_accuracy: 0.0780\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 213ms/step - loss: 0.2882 - accuracy: 0.0866 - val_loss: 0.2788 - val_accuracy: 0.1561\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2776 - accuracy: 0.1098 - val_loss: 0.2747 - val_accuracy: 0.1122\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2739 - accuracy: 0.1122 - val_loss: 0.2718 - val_accuracy: 0.1268\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 6s 223ms/step - loss: 0.2705 - accuracy: 0.1256 - val_loss: 0.2696 - val_accuracy: 0.2000\n"
     ]
    },
    {
     "ename": "PermissionDeniedError",
     "evalue": "/mnt; Read-only file system",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 31\u001b[0m\n\u001b[1;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     23\u001b[0m     [X_train_text, X_train_stats],\n\u001b[1;32m     24\u001b[0m     y_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Save model and label binarizer\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/mnt/data/rnn_stats_pokemon_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(mlb\u001b[38;5;241m.\u001b[39mclasses_, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mnt/data/type_classes.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/datascience/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/miniconda3/envs/datascience/lib/python3.9/site-packages/tensorflow/python/lib/io/file_io.py:513\u001b[0m, in \u001b[0;36mrecursive_create_dir_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio.gfile.makedirs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_create_dir_v2\u001b[39m(path):\n\u001b[1;32m    503\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a directory and all parent/intermediate directories.\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \n\u001b[1;32m    505\u001b[0m \u001b[38;5;124;03m  It succeeds if path already exists and is writable.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03m    errors.OpError: If the operation fails.\u001b[39;00m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 513\u001b[0m   \u001b[43m_pywrap_file_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRecursivelyCreateDir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mPermissionDeniedError\u001b[0m: /mnt; Read-only file system"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "X_train_text, X_test_text, X_train_stats, X_test_stats, y_train, y_test = train_test_split(\n",
    "    X_text, X_stats, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the RNN + Stats model\n",
    "input_text = Input(shape=(300,), name='text_input')\n",
    "text_embed = Embedding(input_dim=5000, output_dim=64, input_length=300)(input_text)\n",
    "text_lstm = LSTM(64)(text_embed)\n",
    "\n",
    "input_stats = Input(shape=(X_stats.shape[1],), name='stats_input')\n",
    "\n",
    "combined = Concatenate()([text_lstm, input_stats])\n",
    "hidden = Dense(128, activation='relu')(combined)\n",
    "output = Dense(len(mlb.classes_), activation='sigmoid')(hidden)\n",
    "\n",
    "model = Model(inputs=[input_text, input_stats], outputs=output)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    [X_train_text, X_train_stats],\n",
    "    y_train,\n",
    "    validation_data=([X_test_text, X_test_stats], y_test),\n",
    "    epochs=5,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Save model and label binarizer\n",
    "model.save(\"rnn_stats_pokemon_model\")\n",
    "pd.DataFrame(mlb.classes_, columns=['Type']).to_csv(\"/mnt/data/type_classes.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
